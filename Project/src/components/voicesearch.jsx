import React, { useState, useEffect, useRef } from 'react';

const VoiceSearch = ({ searchTerm, setSearchTerm }) => {
  const [listening, setListening] = useState(false);
  const [interimTranscript, setInterimTranscript] = useState('');  // ì¤‘ê°„ ì¸ì‹ ê²°ê³¼ ì €ì¥
  const recognitionRef = useRef(null);

  useEffect(() => {
    if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
      alert('ì´ ë¸Œë¼ìš°ì €ëŠ” ìŒì„± ì¸ì‹ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
      return;
    }

    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();

    recognition.lang = 'ko-KR';
    recognition.interimResults = true;   // ì¤‘ê°„ ê²°ê³¼ë„ ë°›ê¸° ìœ„í•´ true
    recognition.continuous = false;

    recognition.onstart = () => {
      setListening(true);
      setInterimTranscript('');  // ì‹œì‘í•˜ë©´ ì´ˆê¸°í™”
    };

    recognition.onresult = (event) => {
      let interim = '';
      let final = '';

      for (let i = event.resultIndex; i < event.results.length; i++) {
        if (event.results[i].isFinal) {
          final += event.results[i][0].transcript;
        } else {
          interim += event.results[i][0].transcript;
        }
      }

      if (final) {
        const cleaned = final.trim();
        console.log("ğŸ™ ìµœì¢… ìŒì„± ì¸ì‹ ê²°ê³¼:", cleaned);
        setInterimTranscript(cleaned);
        setSearchTerm(cleaned);  // âœ… ì—¬ê¸°ì„œ ì§ì ‘ ì „ë‹¬
      } else {
        setInterimTranscript(interim);
      }
    };

    recognition.onend = () => {
      setListening(false);
      console.log("ìŒì„± ì¸ì‹ ê²°ê³¼(ìµœì¢…):", interimTranscript || searchTerm);

      const finalTerm = interimTranscript || searchTerm;

      // ë¹ˆ ë¬¸ìì—´ì´ë©´ setSearchTerm í˜¸ì¶œí•˜ì§€ ì•ŠìŒ
      if (finalTerm && finalTerm.trim() !== '') {
        setSearchTerm(finalTerm);
      }

      setInterimTranscript('');
    };

    recognitionRef.current = recognition;
  }, [setSearchTerm, searchTerm, interimTranscript]);

  const toggleListening = () => {
    if (listening) {
      recognitionRef.current.stop();
    } else {
      recognitionRef.current.start();
    }
  };

  return (
    <>
      <button
        onClick={toggleListening}
        className="mic-button"
        aria-label="search start/stop"
        style={{ background: 'none', border: 'none', cursor: 'pointer', position: 'absolute', right: '10px', top: '50%', transform: 'translateY(-50%)' }}
      >
        <img
          src="png/mic.png"
          alt={listening ? "recoding" : "mic"}
          style={{ width: '15px', height: '20px', filter: listening ? 'invert(33%) sepia(100%) saturate(635%) hue-rotate(174deg) brightness(98%) contrast(92%)' : 'none' }}
        />
      </button>

      {/* ìŒì„± ì¸ì‹ ì¤‘ íŒì—… ì°½ */}
      {listening && (
        <div style={{
          position: 'fixed',
          top: '30%',
          left: '50%',
          transform: 'translateX(-50%)',
          padding: '20px 30px',
          backgroundColor: 'rgba(0, 0, 0, 0.6)',
          color: 'white',
          borderRadius: '10px',
          fontSize: '18px',
          zIndex: 9999,
          maxWidth: '80%',
          textAlign: 'center',
          boxShadow: '0 4px 15px rgba(0,0,0,0.3)',
        }}>
          <p>ë§í•˜ëŠ” ì¤‘...</p>
          <p style={{marginTop: '10px', fontWeight: 'bold'}}>
            {interimTranscript || 'ìŒì„± ì¸ì‹ ëŒ€ê¸° ì¤‘...'}
          </p>
          <small style={{opacity: 0.7}}>ë§ˆì´í¬ ì•„ì´ì½˜ì„ ë‹¤ì‹œ ëˆŒëŸ¬ ìŒì„± ì¸ì‹ì„ ì¢…ë£Œí•˜ì„¸ìš”.</small>
        </div>
      )}
    </>
  );
};

export default VoiceSearch;
